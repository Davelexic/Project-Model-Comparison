{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### lstm_predictor_project2-2.ipynb - 3 yrs AAPL data - LSTM"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# LSTM Stock Predictor Using Closing Prices"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Preparation\n",
    "\n",
    "In this section, we will prepare the training and testing data for the LSTM model.\n",
    "\n",
    "We will need to:\n",
    "1. Use the `window_data` function to generate the X and y values for the model.\n",
    "2. Split the data into 70% training and 30% testing\n",
    "3. Apply the MinMaxScaler to the `X` and `y` values\n",
    "4. Reshape the `X_train` and `X_test` data for the model.\n",
    "\n",
    "**Note:** The required input format for the LSTM is:\n",
    "\n",
    "```python\n",
    "reshape((X_train.shape[0], X_train.shape[1], 1))\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Bad key savefig.frameon in file C:\\Users\\chakravartiraghavan\\anaconda3\\envs\\deepenv\\lib\\site-packages\\matplotlib\\mpl-data\\stylelib\\_classic_test.mplstyle, line 421 ('savefig.frameon : True')\n",
      "You probably need to get an updated matplotlibrc file from\n",
      "https://github.com/matplotlib/matplotlib/blob/v3.3.2/matplotlibrc.template\n",
      "or from the matplotlib source distribution\n",
      "\n",
      "Bad key verbose.level in file C:\\Users\\chakravartiraghavan\\anaconda3\\envs\\deepenv\\lib\\site-packages\\matplotlib\\mpl-data\\stylelib\\_classic_test.mplstyle, line 472 ('verbose.level  : silent      # one of silent, helpful, debug, debug-annoying')\n",
      "You probably need to get an updated matplotlibrc file from\n",
      "https://github.com/matplotlib/matplotlib/blob/v3.3.2/matplotlibrc.template\n",
      "or from the matplotlib source distribution\n",
      "\n",
      "Bad key verbose.fileo in file C:\\Users\\chakravartiraghavan\\anaconda3\\envs\\deepenv\\lib\\site-packages\\matplotlib\\mpl-data\\stylelib\\_classic_test.mplstyle, line 473 ('verbose.fileo  : sys.stdout  # a log filename, sys.stdout or sys.stderr')\n",
      "You probably need to get an updated matplotlibrc file from\n",
      "https://github.com/matplotlib/matplotlib/blob/v3.3.2/matplotlibrc.template\n",
      "or from the matplotlib source distribution\n"
     ]
    }
   ],
   "source": [
    "# Initial imports\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from pathlib import Path\n",
    "\n",
    "%matplotlib inline\n",
    "import yfinance as yf\n",
    "import matplotlib.pyplot as plt\n",
    "import mplfinance as mpf\n",
    "import matplotlib.dates as mpl_dates\n",
    "from datetime import date, timedelta\n",
    "import calendar\n",
    "from datetime import datetime"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set the random seed for reproducibility\n",
    "# Note: This is used for model prototyping, but it is good practice to comment this out and run multiple experiments to evaluate your model.\n",
    "from numpy.random import seed\n",
    "\n",
    "seed(1)\n",
    "from tensorflow import random\n",
    "\n",
    "random.set_seed(2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Data Loading\n",
    "\n",
    "In this activity, we will use closing prices from different stocks to make predictions of future closing prices based on the temporal data of each stock."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "#set ticker\n",
    "appl=yf.Ticker(\"AAPL\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get stock info\n",
    "appl.info\n",
    "\n",
    "# get historical market data\n",
    "hist = appl.history(period=\"max\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[*********************100%***********************]  1 of 1 completed\n"
     ]
    }
   ],
   "source": [
    "#download data\n",
    "df = yf.download(\"AAPL\",\n",
    "                   start=\"2018-07-04\", \n",
    "                   end=\"2021-07-09\",\n",
    "                   period = \"1d\"\n",
    "                  )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Open</th>\n",
       "      <th>High</th>\n",
       "      <th>Low</th>\n",
       "      <th>Close</th>\n",
       "      <th>Adj Close</th>\n",
       "      <th>Volume</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Date</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2018-07-05</th>\n",
       "      <td>46.314999</td>\n",
       "      <td>46.602501</td>\n",
       "      <td>46.070000</td>\n",
       "      <td>46.349998</td>\n",
       "      <td>44.747585</td>\n",
       "      <td>66416800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2018-07-06</th>\n",
       "      <td>46.355000</td>\n",
       "      <td>47.107498</td>\n",
       "      <td>46.299999</td>\n",
       "      <td>46.992500</td>\n",
       "      <td>45.367878</td>\n",
       "      <td>69940800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2018-07-09</th>\n",
       "      <td>47.375000</td>\n",
       "      <td>47.669998</td>\n",
       "      <td>47.325001</td>\n",
       "      <td>47.645000</td>\n",
       "      <td>45.997814</td>\n",
       "      <td>79026400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2018-07-10</th>\n",
       "      <td>47.677502</td>\n",
       "      <td>47.820000</td>\n",
       "      <td>47.544998</td>\n",
       "      <td>47.587502</td>\n",
       "      <td>45.942310</td>\n",
       "      <td>63756400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2018-07-11</th>\n",
       "      <td>47.125000</td>\n",
       "      <td>47.445000</td>\n",
       "      <td>46.902500</td>\n",
       "      <td>46.970001</td>\n",
       "      <td>45.346149</td>\n",
       "      <td>75326000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2018-07-12</th>\n",
       "      <td>47.382500</td>\n",
       "      <td>47.852501</td>\n",
       "      <td>47.327499</td>\n",
       "      <td>47.757500</td>\n",
       "      <td>46.106426</td>\n",
       "      <td>72164400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2018-07-13</th>\n",
       "      <td>47.770000</td>\n",
       "      <td>47.959999</td>\n",
       "      <td>47.724998</td>\n",
       "      <td>47.832500</td>\n",
       "      <td>46.178841</td>\n",
       "      <td>50055600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2018-07-16</th>\n",
       "      <td>47.880001</td>\n",
       "      <td>48.162498</td>\n",
       "      <td>47.605000</td>\n",
       "      <td>47.727501</td>\n",
       "      <td>46.077469</td>\n",
       "      <td>60172400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2018-07-17</th>\n",
       "      <td>47.437500</td>\n",
       "      <td>47.967499</td>\n",
       "      <td>47.299999</td>\n",
       "      <td>47.862499</td>\n",
       "      <td>46.207802</td>\n",
       "      <td>62138000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2018-07-18</th>\n",
       "      <td>47.945000</td>\n",
       "      <td>47.950001</td>\n",
       "      <td>47.482498</td>\n",
       "      <td>47.599998</td>\n",
       "      <td>45.954376</td>\n",
       "      <td>65573600</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                 Open       High        Low      Close  Adj Close    Volume\n",
       "Date                                                                       \n",
       "2018-07-05  46.314999  46.602501  46.070000  46.349998  44.747585  66416800\n",
       "2018-07-06  46.355000  47.107498  46.299999  46.992500  45.367878  69940800\n",
       "2018-07-09  47.375000  47.669998  47.325001  47.645000  45.997814  79026400\n",
       "2018-07-10  47.677502  47.820000  47.544998  47.587502  45.942310  63756400\n",
       "2018-07-11  47.125000  47.445000  46.902500  46.970001  45.346149  75326000\n",
       "2018-07-12  47.382500  47.852501  47.327499  47.757500  46.106426  72164400\n",
       "2018-07-13  47.770000  47.959999  47.724998  47.832500  46.178841  50055600\n",
       "2018-07-16  47.880001  48.162498  47.605000  47.727501  46.077469  60172400\n",
       "2018-07-17  47.437500  47.967499  47.299999  47.862499  46.207802  62138000\n",
       "2018-07-18  47.945000  47.950001  47.482498  47.599998  45.954376  65573600"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# # Load the stocks data\n",
    "# df = pd.read_csv(\n",
    "#     Path(\"../Resources/stock_data.csv\"),\n",
    "#     index_col=\"date\",\n",
    "#     infer_datetime_format=True,\n",
    "#     parse_dates=True,\n",
    "# )\n",
    "df.head(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Creating the Features `X` and Target `y` Data\n",
    "\n",
    "The first step towards preparing the data is to create the input features vectors `X` and the target vector `y`. We will use the `window_data()` function to create these vectors.\n",
    "\n",
    "This function chunks the data up with a rolling window of _X<sub>t</sub> - window_ to predict _X<sub>t</sub>_.\n",
    "\n",
    "The function returns two `numpy` arrays:\n",
    "\n",
    "* `X`: The input features vectors.\n",
    "\n",
    "* `y`: The target vector.\n",
    "\n",
    "The function has the following parameters:\n",
    "\n",
    "* `df`: The original DataFrame with the time series data.\n",
    "\n",
    "* `window`: The window size in days of previous closing prices that will be used for the prediction.\n",
    "\n",
    "* `feature_col_number`: The column number from the original DataFrame where the features are located.\n",
    "\n",
    "* `target_col_number`: The column number from the original DataFrame where the target is located."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def window_data(df, window, feature_col_number, target_col_number):\n",
    "    \"\"\"\n",
    "    This function accepts the column number for the features (X) and the target (y).\n",
    "    It chunks the data up with a rolling window of Xt - window to predict Xt.\n",
    "    It returns two numpy arrays of X and y.\n",
    "    \"\"\"\n",
    "    X = []\n",
    "    y = []\n",
    "    for i in range(len(df) - window):\n",
    "        features = df.iloc[i : (i + window), feature_col_number]\n",
    "        target = df.iloc[(i + window), target_col_number]\n",
    "        X.append(features)\n",
    "        y.append(target)\n",
    "    return np.array(X), np.array(y).reshape(-1, 1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In the forthcoming activities, we will predict closing prices using a `5` days windows of previous _T-Bonds_ closing prices, so that, we will create the `X` and `y` vectors by calling the `window_data` function and defining a window size of `5` and setting the features and target column numbers to `2` (this is the column with the _T-Bonds_ closing prices)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X sample values:\n",
      "[[46.34999847 46.99250031 47.64500046 47.58750153 46.97000122]\n",
      " [46.99250031 47.64500046 47.58750153 46.97000122 47.75749969]\n",
      " [47.64500046 47.58750153 46.97000122 47.75749969 47.83250046]\n",
      " [47.58750153 46.97000122 47.75749969 47.83250046 47.72750092]\n",
      " [46.97000122 47.75749969 47.83250046 47.72750092 47.86249924]] \n",
      "\n",
      "y sample values:\n",
      "[[47.75749969]\n",
      " [47.83250046]\n",
      " [47.72750092]\n",
      " [47.86249924]\n",
      " [47.59999847]]\n"
     ]
    }
   ],
   "source": [
    "# Creating the features (X) and target (y) data using the window_data() function.\n",
    "window_size = 5\n",
    "\n",
    "feature_column = 3\n",
    "target_column = 3\n",
    "X, y = window_data(df, window_size, feature_column, target_column)\n",
    "print (f\"X sample values:\\n{X[:5]} \\n\")\n",
    "print (f\"y sample values:\\n{y[:5]}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Splitting Data Between Training and Testing Sets\n",
    "\n",
    "To avoid the dataset being randomized, we will manually split the data using array slicing."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Use 70% of the data for training and the remainder for testing\n",
    "split = int(0.7 * len(X))\n",
    "X_train = X[: split]\n",
    "X_test = X[split:]\n",
    "y_train = y[: split]\n",
    "y_test = y[split:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "753"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "527"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 46.34999847,  46.99250031,  47.64500046,  47.58750153,\n",
       "         46.97000122],\n",
       "       [ 46.99250031,  47.64500046,  47.58750153,  46.97000122,\n",
       "         47.75749969],\n",
       "       [ 47.64500046,  47.58750153,  46.97000122,  47.75749969,\n",
       "         47.83250046],\n",
       "       ...,\n",
       "       [109.66500092, 110.0625    , 113.90249634, 111.11250305,\n",
       "        112.72750092],\n",
       "       [110.0625    , 113.90249634, 111.11250305, 112.72750092,\n",
       "        109.375     ],\n",
       "       [113.90249634, 111.11250305, 112.72750092, 109.375     ,\n",
       "        113.01000214]])"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Scaling Data with `MinMaxScaler`\n",
    "\n",
    "Once the training and test datasets are created, we need to scale the data before training the LSTM model. We will use the `MinMaxScaler` from `sklearn` to scale all values between `0` and `1`.\n",
    "\n",
    "Note that we scale both features and target sets."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Use the MinMaxScaler to scale data between 0 and 1.\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "\n",
    "scaler = MinMaxScaler()\n",
    "scaler.fit(X)\n",
    "X_train = scaler.transform(X_train)\n",
    "X_test = scaler.transform(X_test)\n",
    "scaler.fit(y)\n",
    "y_train = scaler.transform(y_train)\n",
    "y_test = scaler.transform(y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.1003833 , 0.10635381, 0.11241723, 0.11188292, 0.10477195],\n",
       "       [0.10635381, 0.11241723, 0.11188292, 0.10614473, 0.11199522],\n",
       "       [0.11241723, 0.11188292, 0.10614473, 0.11346264, 0.11268315],\n",
       "       ...,\n",
       "       [0.68874432, 0.69243812, 0.72812167, 0.70219538, 0.70792722],\n",
       "       [0.69243812, 0.72812167, 0.70219538, 0.71720291, 0.67717668],\n",
       "       [0.72812167, 0.70219538, 0.71720291, 0.68604946, 0.71051844]])"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Reshape Features Data for the LSTM Model\n",
    "\n",
    "The LSTM API from Keras needs to receive the features data as a _vertical vector_, so that we need to reshape the `X` data in the form `reshape((X_train.shape[0], X_train.shape[1], 1))`.\n",
    "\n",
    "Both sets, training, and testing are reshaped."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X_train sample values:\n",
      "[[[0.1003833 ]\n",
      "  [0.10635381]\n",
      "  [0.11241723]\n",
      "  [0.11188292]\n",
      "  [0.10477195]]\n",
      "\n",
      " [[0.10635381]\n",
      "  [0.11241723]\n",
      "  [0.11188292]\n",
      "  [0.10614473]\n",
      "  [0.11199522]]\n",
      "\n",
      " [[0.11241723]\n",
      "  [0.11188292]\n",
      "  [0.10614473]\n",
      "  [0.11346264]\n",
      "  [0.11268315]]\n",
      "\n",
      " [[0.11188292]\n",
      "  [0.10614473]\n",
      "  [0.11346264]\n",
      "  [0.1141596 ]\n",
      "  [0.11172005]]\n",
      "\n",
      " [[0.10614473]\n",
      "  [0.11346264]\n",
      "  [0.1141596 ]\n",
      "  [0.11318388]\n",
      "  [0.11295831]]] \n",
      "\n",
      "X_test sample values:\n",
      "[[[0.70219538]\n",
      "  [0.71720291]\n",
      "  [0.68604946]\n",
      "  [0.71982808]\n",
      "  [0.72886328]]\n",
      "\n",
      " [[0.71720291]\n",
      "  [0.68604946]\n",
      "  [0.71982808]\n",
      "  [0.73841328]\n",
      "  [0.7279231 ]]\n",
      "\n",
      " [[0.68604946]\n",
      "  [0.71982808]\n",
      "  [0.73841328]\n",
      "  [0.73746078]\n",
      "  [0.72517134]]\n",
      "\n",
      " [[0.71982808]\n",
      "  [0.73841328]\n",
      "  [0.73746078]\n",
      "  [0.73467297]\n",
      "  [0.73393102]]\n",
      "\n",
      " [[0.73841328]\n",
      "  [0.73746078]\n",
      "  [0.73467297]\n",
      "  [0.74354742]\n",
      "  [0.73526099]]]\n"
     ]
    }
   ],
   "source": [
    "# Reshape the features for the model\n",
    "X_train = X_train.reshape((X_train.shape[0], X_train.shape[1], 1))\n",
    "X_test = X_test.reshape((X_test.shape[0], X_test.shape[1], 1))\n",
    "print (f\"X_train sample values:\\n{X_train[:5]} \\n\")\n",
    "print (f\"X_test sample values:\\n{X_test[:5]}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## Build and Train the LSTM RNN\n",
    "\n",
    "In this section, we will design a custom LSTM RNN in Keras and fit (train) it using the training data we defined.\n",
    "\n",
    "We will need to:\n",
    "\n",
    "1. Define the model architecture in Keras.\n",
    "\n",
    "2. Compile the model.\n",
    "\n",
    "3. Fit the model to the training data."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Importing the Keras Modules\n",
    "\n",
    "The LSTM RNN model in Keras uses the `Sequential` model and the `LSTM` layer as we did before. However, there is a new type of layer called `Dropout`.\n",
    "\n",
    "* `Dropout`: Dropout is a regularization technique for reducing overfitting in neural networks. This type of layer applies the dropout technique to the input."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import required Keras modules\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import LSTM, Dense, Dropout"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Defining the LSTM RNN Model Structure\n",
    "\n",
    "To create an LSTM RNN model, we will add `LSTM` layers. The `return_sequences` parameter needs to set to `True` every time we add a new `LSTM` layer, excluding the final layer. The `input_shape` is the number of time steps and the number of indicators\n",
    "\n",
    "After each `LSTM` layer, we add a `Dropout` layer to prevent overfitting. The parameter passed to the `Dropout` layer is the fraction of nodes that will be drop on each epoch, for this demo, we will use a dropout value of `0.2`, it means that on each epoch we will randomly drop `20%` of the units.\n",
    "\n",
    "The number of units in each `LSTM` layers, is equal to the size of the time window, in this demo, we are taking five previous `T-Bons` closing price to predict the next closing price."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the LSTM RNN model.\n",
    "model = Sequential()\n",
    "\n",
    "number_units = 5\n",
    "dropout_fraction = 0.2\n",
    "\n",
    "# Layer 1\n",
    "model.add(LSTM(\n",
    "    units=number_units,\n",
    "    return_sequences=True,\n",
    "    input_shape=(X_train.shape[1], 1))\n",
    "    )\n",
    "model.add(Dropout(dropout_fraction))\n",
    "# Layer 2\n",
    "model.add(LSTM(units=number_units, return_sequences=True))\n",
    "model.add(Dropout(dropout_fraction))\n",
    "# Layer 3\n",
    "model.add(LSTM(units=number_units))\n",
    "model.add(Dropout(dropout_fraction))\n",
    "# Output layer\n",
    "model.add(Dense(1))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Compiling the LSTM RNN Model\n",
    "\n",
    "We will compile the model, using the `adam` optimizer, as loss function, we will use `mean_square_error` since the value we want to predict is continuous."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compile the model\n",
    "model.compile(optimizer=\"adam\", loss=\"mean_squared_error\", metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "lstm (LSTM)                  (None, 5, 5)              140       \n",
      "_________________________________________________________________\n",
      "dropout (Dropout)            (None, 5, 5)              0         \n",
      "_________________________________________________________________\n",
      "lstm_1 (LSTM)                (None, 5, 5)              220       \n",
      "_________________________________________________________________\n",
      "dropout_1 (Dropout)          (None, 5, 5)              0         \n",
      "_________________________________________________________________\n",
      "lstm_2 (LSTM)                (None, 5)                 220       \n",
      "_________________________________________________________________\n",
      "dropout_2 (Dropout)          (None, 5)                 0         \n",
      "_________________________________________________________________\n",
      "dense (Dense)                (None, 1)                 6         \n",
      "=================================================================\n",
      "Total params: 586\n",
      "Trainable params: 586\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "# Summarize the model\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Training the Model\n",
    "\n",
    "Once the model is defined, we train (fit) the model using `10` epochs. Since we are working with time-series data, it's important to set `shuffle=False` since it's necessary to keep the sequential order of the data.\n",
    "\n",
    "We can experiment with the `batch_size` parameter; however, smaller batch size is recommended; in this demo, we will use a `batch_size=1`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "527/527 [==============================] - 31s 9ms/step - loss: 0.0036 - accuracy: 0.0019\n",
      "Epoch 2/10\n",
      "527/527 [==============================] - 4s 7ms/step - loss: 0.0095 - accuracy: 0.0019\n",
      "Epoch 3/10\n",
      "527/527 [==============================] - 4s 8ms/step - loss: 0.0078 - accuracy: 0.0019\n",
      "Epoch 4/10\n",
      "527/527 [==============================] - 4s 7ms/step - loss: 0.0051 - accuracy: 0.0019\n",
      "Epoch 5/10\n",
      "527/527 [==============================] - 4s 8ms/step - loss: 0.0040 - accuracy: 0.0019\n",
      "Epoch 6/10\n",
      "527/527 [==============================] - 4s 7ms/step - loss: 0.0029 - accuracy: 0.0019\n",
      "Epoch 7/10\n",
      "527/527 [==============================] - 4s 7ms/step - loss: 0.0027 - accuracy: 0.0019\n",
      "Epoch 8/10\n",
      "527/527 [==============================] - 3s 6ms/step - loss: 0.0027 - accuracy: 0.0019\n",
      "Epoch 9/10\n",
      "270/527 [==============>...............] - ETA: 1s - loss: 0.0022 - accuracy: 0.0037"
     ]
    }
   ],
   "source": [
    "# Train the model\n",
    "model.fit(X_train, y_train, epochs=10, shuffle=False, batch_size=1, verbose=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Train the model\n",
    "model.fit(X_train, y_train, epochs=10, shuffle=False, batch_size=1, verbose=1)\n",
    "\n",
    "Epoch 1/10\n",
    "527/527 [==============================] - 11s 5ms/step - loss: 0.0036 - accuracy: 0.0019\n",
    "Epoch 2/10\n",
    "527/527 [==============================] - 2s 4ms/step - loss: 0.0095 - accuracy: 0.0019\n",
    "Epoch 3/10\n",
    "527/527 [==============================] - 3s 5ms/step - loss: 0.0078 - accuracy: 0.0019\n",
    "Epoch 4/10\n",
    "527/527 [==============================] - 3s 5ms/step - loss: 0.0051 - accuracy: 0.0019\n",
    "Epoch 5/10\n",
    "527/527 [==============================] - 4s 7ms/step - loss: 0.0040 - accuracy: 0.0019\n",
    "Epoch 6/10\n",
    "527/527 [==============================] - 3s 5ms/step - loss: 0.0029 - accuracy: 0.0019\n",
    "Epoch 7/10\n",
    "527/527 [==============================] - 3s 5ms/step - loss: 0.0027 - accuracy: 0.0019\n",
    "Epoch 8/10\n",
    "527/527 [==============================] - 3s 6ms/step - loss: 0.0027 - accuracy: 0.0019: 0s - los\n",
    "Epoch 9/10\n",
    "527/527 [==============================] - 3s 6ms/step - loss: 0.0029 - accuracy: 0.0019\n",
    "Epoch 10/10\n",
    "527/527 [==============================] - 4s 7ms/step - loss: 0.0025 - accuracy: 0.0019: 0s - loss: 0.0021 - ac\n",
    "<tensorflow.python.keras.callbacks.History at 0x1e0c104f048>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_test.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## Model Performance\n",
    "\n",
    "In this section, we will evaluate the model using the test data. \n",
    "\n",
    "We will need to:\n",
    "\n",
    "1. Evaluate the model using the `X_test` and `y_test` data.\n",
    "\n",
    "2. Use the `X_test` data to make predictions.\n",
    "\n",
    "3. Create a DataFrame of real (`y_test`) vs predicted values.\n",
    "\n",
    "4. Plot the Real vs predicted values as a line chart."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Evaluate the Model\n",
    "\n",
    "It's time to evaluate our model to assess its performance. We will use the `evaluate` method using the testing data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Evaluate the model\n",
    "model.evaluate(X_test, y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Making Predictions\n",
    "\n",
    "We will make some closing price predictions using our brand new LSTM RNN model and our testing data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Make some predictions\n",
    "predicted = model.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "predicted.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Since we scaled the original values using the `MinMaxScaler`, we need to recover the original prices to better understand the predictions.\n",
    "\n",
    "We will use the `inverse_transform()` method of the scaler to decode the scaled values to their original scale."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Recover the original prices instead of the scaled version\n",
    "predicted_prices = scaler.inverse_transform(predicted)\n",
    "real_prices = scaler.inverse_transform(y_test.reshape(-1, 1))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Plotting Predicted Vs. Real Prices\n",
    "\n",
    "To plot the predicted vs. the real values, we will create a DataFrame."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a DataFrame of Real and Predicted values\n",
    "stocks = pd.DataFrame({\n",
    "    \"Real\": real_prices.ravel(),\n",
    "    \"Predicted\": predicted_prices.ravel()\n",
    "    }, index = df.index[-len(real_prices): ])\n",
    "stocks.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "stocks.tail()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot the real vs predicted prices as a line chart\n",
    "stocks.plot()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "file_extension": ".py",
  "kernelspec": {
   "display_name": "Python [conda env:deepenv] *",
   "language": "python",
   "name": "conda-env-deepenv-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.9"
  },
  "mimetype": "text/x-python",
  "name": "python",
  "npconvert_exporter": "python",
  "pygments_lexer": "ipython3",
  "version": 3
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
